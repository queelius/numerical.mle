#' Compose Multiple Solvers Sequentially
#'
#' Chains any number of solvers sequentially. Each solver's result becomes
#' the starting point for the next. Alternative to using \code{\%>>\%} operator.
#'
#' @param ... Solver functions to compose
#' @return A new solver function that runs all solvers in sequence
#'
#' @examples
#' \dontrun{
#' # Three-stage strategy
#' strategy <- compose(
#'   grid_search(n = 5),
#'   gradient_ascent(max_iter = 50),
#'   newton_raphson(max_iter = 20)
#' )
#' result <- strategy(problem, theta0)
#' }
#'
#' @export
compose <- function(...) {
  solvers <- list(...)
  stopifnot(length(solvers) >= 1)
  for (s in solvers) stopifnot(is.function(s))

  if (length(solvers) == 1) return(solvers[[1]])

  function(problem, theta0, trace = mle_trace()) {
    result <- solvers[[1]](problem, theta0, trace)
    chain <- list(result)

    for (i in seq_len(length(solvers) - 1) + 1) {
      result <- solvers[[i]](problem, result$theta.hat, trace)
      chain <- c(chain, list(result))
    }

    result$chain <- chain
    result$strategy <- "sequential"
    result
  }
}

#' Sequential Solver Composition
#'
#' Chains two solvers sequentially. The result of the first solver becomes
#' the starting point for the second. This enables coarse-to-fine strategies.
#'
#' @param s1 First solver function
#' @param s2 Second solver function
#' @return A new solver function that runs s1 then s2
#'
#' @examples
#' # Coarse-to-fine: grid search to find good region, then gradient ascent
#' strategy <- grid_search(n = 5) %>>% gradient_ascent()
#'
#' # Three-stage refinement
#' strategy <- grid_search(n = 3) %>>% gradient_ascent() %>>% newton_raphson()
#'
#' @export
`%>>%` <- function(s1, s2) {
 stopifnot(is.function(s1), is.function(s2))

  function(problem, theta0, trace = mle_trace()) {
    # Run first solver
    result1 <- s1(problem, theta0, trace)

    # Run second solver starting from first result
    result2 <- s2(problem, result1$theta.hat, trace)

    # Combine chain information
    result2$chain <- c(
      if (!is.null(result1$chain)) result1$chain else list(result1),
      list(result2)
    )
    result2$strategy <- "sequential"

    result2
  }
}

#' Parallel Solver Racing
#'
#' Runs multiple solvers and returns the best result (highest log-likelihood).
#' Useful when unsure which method will work best for a given problem.
#'
#' @param s1 First solver function
#' @param s2 Second solver function
#' @return A new solver function that runs both and picks the best
#'
#' @examples
#' # Race gradient-based vs derivative-free
#' strategy <- gradient_ascent() %|% nelder_mead()
#'
#' # Race multiple methods
#' strategy <- gradient_ascent() %|% bfgs() %|% nelder_mead()
#'
#' @export
`%|%` <- function(s1, s2) {
  stopifnot(is.function(s1), is.function(s2))

  function(problem, theta0, trace = mle_trace()) {
    # Run both solvers
    result1 <- tryCatch(
      s1(problem, theta0, trace),
      error = function(e) NULL
    )

    result2 <- tryCatch(
      s2(problem, theta0, trace),
      error = function(e) NULL
    )

    # Handle failures
    if (is.null(result1) && is.null(result2)) {
      stop("All solvers in parallel race failed")
    }
    if (is.null(result1)) return(result2)
    if (is.null(result2)) return(result1)

    # Pick best by log-likelihood
    ll1 <- if (!is.null(result1$loglike)) result1$loglike else -Inf
    ll2 <- if (!is.null(result2$loglike)) result2$loglike else -Inf

    winner <- if (ll1 >= ll2) result1 else result2
    winner$alternatives <- list(result1, result2)
    winner$strategy <- "race"

    winner
  }
}

#' Multiple Random Restarts
#'
#' Runs a solver from multiple starting points and returns the best result.
#' Essential for problems with multiple local optima.
#'
#' The sampler generates candidate starting points, which are automatically
#' filtered/projected using the problem's constraint. This means samplers
#' can be simple distributions without constraint awareness.
#'
#' @param solver A solver function
#' @param n Number of restarts (including the provided theta0)
#' @param sampler Function that generates random starting points.
#'   Called with no arguments, should return a parameter vector.
#'   Samples are automatically constrained using problem$constraint.
#' @param max_reject Maximum rejection attempts per sample before projection
#' @return A new solver function with restart capability
#'
#' @examples
#' # 20 random restarts - constraint applied automatically from problem
#' strategy <- gradient_ascent() %>%
#'   with_restarts(n = 20, sampler = uniform_sampler(c(-10, 0), c(10, 5)))
#'
#' # Can also compose with other operators
#' strategy <- gradient_ascent() %>%
#'   with_restarts(n = 10, sampler = uniform_sampler(c(-10, 0), c(10, 5))) %>>%
#'   newton_raphson()
#'
#' @export
with_restarts <- function(solver, n, sampler, max_reject = 100L) {
  stopifnot(is.function(solver))
  stopifnot(is.numeric(n), n >= 1)
  stopifnot(is.function(sampler))

  n <- as.integer(n)
  max_reject <- as.integer(max_reject)

  function(problem, theta0, trace = mle_trace()) {
    constraint <- problem$constraint

    # Helper to generate a valid starting point
    sample_valid <- function() {
      for (attempt in seq_len(max_reject)) {
        theta <- sampler()
        if (constraint$support(theta)) {
          return(theta)
        }
      }
      # Fallback: project onto support
      constraint$project(sampler())
    }

    # Generate starting points: theta0 plus n-1 random samples
    starts <- vector("list", n)
    starts[[1]] <- theta0
    for (i in seq_len(n - 1) + 1) {
      starts[[i]] <- sample_valid()
    }

    # Run solver from each starting point
    results <- vector("list", n)
    loglikes <- rep(-Inf, n)

    for (i in seq_len(n)) {
      results[[i]] <- tryCatch(
        solver(problem, starts[[i]], trace),
        error = function(e) NULL
      )

      if (!is.null(results[[i]]) && !is.null(results[[i]]$loglike)) {
        loglikes[i] <- results[[i]]$loglike
      }
    }

    # Find best
    if (all(loglikes == -Inf)) {
      stop("All restart attempts failed")
    }

    best_idx <- which.max(loglikes)
    best <- results[[best_idx]]

    best$n_restarts <- n
    best$restart_loglikes <- loglikes
    best$best_restart <- best_idx
    best$strategy <- "restarts"

    best
  }
}

#' Conditional Refinement
#'
#' Applies a refinement solver only if the first solver did not converge.
#'
#' @param solver Primary solver function
#' @param refinement Solver to use if primary doesn't converge
#' @return A new solver function with conditional refinement
#'
#' @examples
#' # Use Newton-Raphson to refine if gradient ascent doesn't converge
#' strategy <- gradient_ascent(max_iter = 50) %>%
#'   unless_converged(newton_raphson())
#'
#' @export
unless_converged <- function(solver, refinement) {
  stopifnot(is.function(solver), is.function(refinement))

  function(problem, theta0, trace = mle_trace()) {
    result <- solver(problem, theta0, trace)

    if (!isTRUE(result$converged)) {
      result2 <- refinement(problem, result$theta.hat, trace)
      result2$chain <- c(list(result), list(result2))
      result2$strategy <- "conditional"
      return(result2)
    }

    result
  }
}

#' Uniform Sampler Factory
#'
#' Creates a sampler function for use with \code{with_restarts} that
#' generates uniformly distributed starting points.
#'
#' @param lower Lower bounds for each parameter
#' @param upper Upper bounds for each parameter
#' @return A sampler function
#'
#' @examples
#' sampler <- uniform_sampler(c(-10, 0.1), c(10, 5))
#' strategy <- gradient_ascent() %>% with_restarts(n = 20, sampler = sampler)
#'
#' @export
uniform_sampler <- function(lower, upper) {
  stopifnot(length(lower) == length(upper))
  stopifnot(all(lower <= upper))

  function() {
    runif(length(lower), min = lower, max = upper)
  }
}

#' Normal Sampler Factory
#'
#' Creates a sampler function for use with \code{with_restarts} that
#' generates normally distributed starting points around a center.
#'
#' @param center Mean of the normal distribution
#' @param sd Standard deviation (scalar or vector)
#' @return A sampler function
#'
#' @examples
#' sampler <- normal_sampler(c(0, 1), sd = c(5, 0.5))
#' strategy <- gradient_ascent() %>% with_restarts(n = 20, sampler = sampler)
#'
#' @export
normal_sampler <- function(center, sd = 1) {
  if (length(sd) == 1) sd <- rep(sd, length(center))
  stopifnot(length(center) == length(sd))

  function() {
    rnorm(length(center), mean = center, sd = sd)
  }
}

